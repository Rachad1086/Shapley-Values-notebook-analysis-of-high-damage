{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developped Framework for High DEL Period Analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify project_path\n",
    "project_path = r'your_path_to_the_project_folder'\n",
    "\n",
    "# Load the model\n",
    "from py_nw2.mlflow_functions import load_model\n",
    "from py_nw2.model import custom_loss\n",
    "\n",
    "model_folder_path = os.path.join(project_path, 'models') # path of the folder where the model is saved\n",
    "model_name = 'DEL_NRT_PB_Mtn_1' # name of the model\n",
    "model_path = os.path.join(model_folder_path, model_name) # path of the model\n",
    "model = load_model(dir_path=model_path, custom_objects={'custom_loss':custom_loss}) # load the model\n",
    "\n",
    "features_names = list(model.info['input_features']) # get the features names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data for testing\n",
    "data_folder_path = os.path.join(project_path, 'data') # path of the folder where the data is saved\n",
    "input_data = pd.read_parquet(os.path.join(data_folder_path, 'normalized2', 'turbine1_normalized_data.parquet')) # load the data\n",
    "turbine_x = 'turbine 1' # name of the turbine\n",
    "\n",
    "# Print the period of the data\n",
    "print(turbine_x,'data shape :',input_data.shape)\n",
    "print(turbine_x,'period :',input_data.index[0],'-',input_data.index[-1])\n",
    "\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the DEL predictions (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the predictions\n",
    "predictions_turbine = pd.DataFrame({'DEL': model.predict(input_data).flatten()}, index=input_data.index)\n",
    "\n",
    "# combine input data and output  \n",
    "full_data = pd.concat([input_data, predictions_turbine], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of the DEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(predictions_turbine, label=turbine_x)\n",
    "plt.title('DEL predictions')\n",
    "plt.legend(fontsize='large')  # Increase the font size of the legend\n",
    "plt.ylabel('DEL [Nm]')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection of reference samples for Shapley Values analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to select reference points based on 3 criteria:\n",
    "- DEL < threshold_max\n",
    "- mean_NRT_rpm > threshold_rpm_power\n",
    "- mean_NRT_power > threshold_rpm_power\n",
    "\n",
    "To have the rated conditions\n",
    "\n",
    "number_of_sample : number of reference points to select\n",
    "'''\n",
    "\n",
    "\n",
    "def select_ref_point(df,threshold_max,threshold_rpm_power,number_of_sample):\n",
    "\n",
    "\n",
    "    threshold_max = threshold_max*1000000 # convert to Nm because the DEL order of magnitude is 1e6\n",
    "\n",
    "\n",
    "    df = df[(df['DEL'] < threshold_max)]\n",
    "    print('Number of points after DEL selection :',df.shape[0])\n",
    "\n",
    "    df = df[df['mean_NRT_rpm'] > threshold_rpm_power]\n",
    "    df = df[df['mean_NRT_power'] > threshold_rpm_power]\n",
    "    print('Number of points after rpm and power selection :',df.shape[0])\n",
    "    \n",
    "   \n",
    "    ref_sample = df.sample(n=number_of_sample, random_state=2)\n",
    "    \n",
    "    return ref_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "\n",
    "threshold_max = 1\n",
    "number_of_sample = 10\n",
    "threshold_rpm = 0.9\n",
    "\n",
    "\n",
    "reference_samples = select_ref_point(full_data,threshold_max,threshold_rpm,number_of_sample)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.scatter(full_data.index, full_data['DEL'], label=turbine_x,marker='o', s=1.2, alpha=1)\n",
    "plt.scatter(reference_samples.index, reference_samples['DEL'], color='red', label='ref point')\n",
    "plt.title('DEL predictions')\n",
    "plt.legend(fontsize='large')  # Increase the font size of the legend\n",
    "plt.ylabel('DEL [Nm]')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection of the samples at High DEL periods for Shapley Values analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(full_data.index, full_data['DEL'], label=turbine_x,s = 2)\n",
    "plt.title('DEL predictions')\n",
    "#plt.legend(fontsize='large')\n",
    "plt.ylabel('DEL [Nm]')\n",
    "plt.xlabel('Time')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the period where High DEL are predicted\n",
    "\n",
    "start_date1 = '2022-12-25'\n",
    "end_date1 = '2022-12-31'\n",
    "\n",
    "start_date2 = '2023-01-07'\n",
    "end_date2 = '2023-01-15'\n",
    "\n",
    "start_date3 = '2023-01-28'\n",
    "end_date3 = '2023-02-02'\n",
    "\n",
    "start_date4 = '2023-02-25'\n",
    "end_date4 = '2023-02-27'\n",
    "\n",
    "\n",
    "start_dates = [start_date1,start_date2,start_date3,start_date4]\n",
    "end_dates = [end_date1,end_date2,end_date3,end_date4]\n",
    "\n",
    "number_of_period = len(start_dates)\n",
    "\n",
    "num_points = 10 # Number of points to select for each period\n",
    "\n",
    "threshold = 1.5*10**6 # Minimum Threshold for DEL\n",
    "\n",
    "\n",
    "# Dictionary to hold selected points for each division\n",
    "selected_points_for_shap = {}\n",
    "\n",
    "\n",
    "# Selecting the points for each period\n",
    "for i in range(number_of_period):\n",
    "    full_data_selected = full_data.loc[start_dates[i]:end_dates[i]]   \n",
    "    full_data_selected = full_data_selected[full_data_selected['DEL'] > threshold] \n",
    "    selected_points_for_shap[i] = full_data_selected.sample(n=num_points, random_state=42)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(full_data.index, full_data['DEL'], label=turbine_x,s=   1.5)\n",
    "for i in range(number_of_period):\n",
    "    color = 'red' if i % 2 == 0 else 'yellow'  # Alternating colors\n",
    "    plt.scatter(selected_points_for_shap[i].index, selected_points_for_shap[i]['DEL'], color=color, label='Selected points')\n",
    "\n",
    "plt.title('DEL predictions')\n",
    "plt.legend(fontsize='large')\n",
    "plt.ylabel('DEL [Nm]')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interesting_features = ['mean_NRT_windspeed','std_NRT_windspeed',\n",
    "                        'mean_NRT_yaw','mean_NRT_power','mean_NRT_pitch',\n",
    "                        'mean_NRT_rpm','mean_NRT_winddirection',\n",
    "                        'mean_NRT_NAC_ACC_Z','rms_NRT_NAC_ACC_FA',\n",
    "                        'rms_NRT_NAC_ACC_SS','rms_NRT_NAC_ACC_Z',\n",
    "                        'mean_NRT_ti','rms1p_NRT_NAC_ACC_Z',\n",
    "                        'rms1p_NRT_NAC_ACC_FA','rms1p_NRT_NAC_ACC_SS']\n",
    "\n",
    "for feature in enumerate(interesting_features):\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.plot(full_data[feature[1]], label=turbine_x)\n",
    "    plt.scatter(reference_samples.index, reference_samples[feature[1]], color='red', label='ref point', zorder=5)\n",
    "    plt.legend()\n",
    "    plt.xlabel('time', fontsize=14)\n",
    "    plt.ylabel(feature[1], fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapley Values Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background samples selection is performed to approximate the Shapley Values. Increasing the number of samples enhances the accuracy of the approximation. However, there is a trade-off between precision and computational time. A recommended sample size is 400, chosen randomly from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# Summarize the background dataset using shap.sample\n",
    "\n",
    "n = 400 # number of samples to summarize the background data\n",
    "background_samples = shap.sample(input_data, n) # summarize the background data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley values for the reference Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the shap values\n",
    "\n",
    "explainer = shap.KernelExplainer(model.predict, background_samples)\n",
    "shap_values_ref = explainer.shap_values(reference_samples[features_names])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plot of the reference period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_exp_ref = shap.Explanation(values=shap_values_ref[0],base_values=explainer.expected_value, feature_names=features_names)\n",
    "Number_of_ft_plot = 10 # Number of features to plot\n",
    "shap.plots.bar(shap_exp_ref.mean(0),max_display=Number_of_ft_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Values of the features\n",
    "\n",
    "Print the mean values of the features ordered by their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the absolute sum of SHAP values for each feature\n",
    "shap_abs_sum = np.abs(shap_values_ref[0].sum(axis=0))\n",
    "\n",
    "# Sort the features based on their absolute sum of SHAP values in descending order\n",
    "sorted_features = sorted(zip(features_names, shap_abs_sum), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create a list of the most important features\n",
    "most_important_features = [feature for feature, _ in sorted_features]\n",
    "\n",
    "\n",
    "# Calculate the average value of each feature for the reference_samples\n",
    "average_values = np.mean(reference_samples[features_names], axis=0)\n",
    "\n",
    "# Sort features and average values based on importance list\n",
    "sorted_features_names = [feature for feature in most_important_features if feature in features_names]\n",
    "sorted_indices = [features_names.index(feature) for feature in sorted_features_names]\n",
    "sorted_average_values = average_values[sorted_indices]\n",
    "for feature in most_important_features:\n",
    "    value = average_values[feature]\n",
    "    value = round(value, 2)\n",
    "    print(f\"{feature}: {value}\")\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley values for the periods of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shap_values_all = {} # Dictionary to hold the shap values for each period\n",
    "\n",
    "for i in range(number_of_period):\n",
    "\n",
    "    # Computing the shap values for each period\n",
    "\n",
    "    explainer = shap.KernelExplainer(model.predict, background_samples)\n",
    "    shap_values_all[i] = explainer.shap_values(selected_points_for_shap[i][features_names])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_number = 3 # Period number to plot the bar plot (the period count starts from 0)\n",
    "shap_exp = shap.Explanation(values=shap_values_all[period_number][0], base_values=explainer.expected_value,feature_names=features_names)\n",
    "print('Shape of the shap value matrix',shap_exp.shape)\n",
    "shap.plots.bar(shap_exp.mean(0),max_display=21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Values of the features in the selected period\n",
    "\n",
    "Print the mean values of the features ordered by their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute sum of SHAP values for each feature\n",
    "shap_abs_sum = abs(shap_values_all[period_number][0].sum(axis=0))\n",
    "\n",
    "# Sort the features based on their absolute sum of SHAP values in descending order\n",
    "sorted_features = sorted(zip(features_names, shap_abs_sum), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create a list of the most important features\n",
    "most_important_features = [feature for feature, _ in sorted_features]\n",
    "\n",
    "\n",
    "# Calculate the average value of each feature for the reference_samples\n",
    "average_values = np.mean(selected_points_for_shap[period_number][features_names], axis=0)\n",
    "\n",
    "# Sort features and average values based on importance list\n",
    "sorted_features_names = [feature for feature in most_important_features if feature in features_names]\n",
    "sorted_indices = [features_names.index(feature) for feature in sorted_features_names]\n",
    "sorted_average_values = average_values[sorted_indices]\n",
    "for feature in most_important_features:\n",
    "    value = average_values[feature]\n",
    "    value = round(value, 2)\n",
    "    print(f\"{feature}: {value}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma_rachad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
